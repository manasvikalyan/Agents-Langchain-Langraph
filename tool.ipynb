{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d86c29",
   "metadata": {},
   "source": [
    "- How To Create Tools\n",
    "- How to use built-in tools and toolkits\n",
    "- How to use chat models to call tools\n",
    "- How to pass tool outputs to chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8580e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manasvi/Github/Agents-Langchain-Langraph/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from langchain_core.tools import tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3014d85",
   "metadata": {},
   "source": [
    "#### creating tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b44b058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mathematics\n",
      "Add, Subtract, Multiply, or Divide two numbers\n",
      "{'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def mathematics(a: float, b: float) -> float:\n",
    "    \"\"\"Add, Subtract, Multiply, or Divide two numbers\"\"\"\n",
    "    return a + b, a-b , a*b , a/b\n",
    "\n",
    "\n",
    "\n",
    "print(mathematics.name)\n",
    "print(mathematics.description)\n",
    "print(mathematics.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b1ddb",
   "metadata": {},
   "source": [
    "### there are lot of other ways of tools as well async, annotated(list), structured tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70d4211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, -1.0, 2.0, 0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematics.invoke({\"a\": 1, \"b\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf8ae1",
   "metadata": {},
   "source": [
    "#### laoding llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8351abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"groq:llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f1311",
   "metadata": {},
   "source": [
    "#### creating agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3aff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an agent from the tool\n",
    "from langchain.agents import create_agent\n",
    "tools = [mathematics]\n",
    "prompt = (\n",
    "    \"\"\"\n",
    "You are a math assistant.\n",
    "\n",
    "When the user gives you two numbers:\n",
    "1. Parse the numbers from the user message.\n",
    "2. Add 2 to each number to get new_a and new_b.\n",
    "3. Call the `mathematics` tool ONCE with a=new_a and b=new_b.\n",
    "4. Then explain to the user:\n",
    "   - The new numbers\n",
    "   - The sum, difference, product, and quotient from the tool. \"\"\"\n",
    ")\n",
    "agent = create_agent(llm, tools, system_prompt=prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e78f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " Numbers are 4 and 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mathematics (xpbvsegsc)\n",
      " Call ID: xpbvsegsc\n",
      "  Args:\n",
      "    a: 6\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mathematics\n",
      "\n",
      "[10.0, 2.0, 24.0, 1.5]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The new numbers are 6 and 4.\n",
      "\n",
      "The sum of the new numbers is 10.\n",
      "The difference between the new numbers is 2.\n",
      "The product of the new numbers is 24.\n",
      "The quotient of the new numbers is 1.5.\n"
     ]
    }
   ],
   "source": [
    "query  = \" Numbers are 4 and 2\"\n",
    "agent.invoke({\"input\": query})\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d186c3",
   "metadata": {},
   "source": [
    "#### using wikipedia pre build tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43447bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max=500)\n",
    "tool=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.invoke({\"query\":\"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fedfa91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### creating wikipedia a tool\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(wiki_tool.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28edf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def mathematics(a: float, b: float) -> float:\n",
    "    \"\"\"Add, Subtract, Multiply, or Divide two numbers\"\"\"\n",
    "    return a + b, a-b , a*b , a/b\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def weather(city: str):\n",
    "    \"\"\"Get current weather-related data for a given city using the Open-Meteo geocoding API.\"\"\"\n",
    "    return requests.get(\n",
    "        f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
    "    ).json()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1450a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [weather, mathematics, wiki_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f234bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is langchain\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (q08pfzap4)\n",
      " Call ID: q08pfzap4\n",
      "  Args:\n",
      "    query: Langchain AI\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (rcjhm9etc)\n",
      " Call ID: rcjhm9etc\n",
      "  Args:\n",
      "    query: Langchain AI use cases\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information provided, LangChain is a software framework that helps integrate large language models into applications, with use cases including document analysis and summarization, chatbots, and code analysis.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the user's question based on the information provided.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    system_prompt=prompt,\n",
    ")\n",
    "\n",
    "\n",
    "query  = \"what is langchain\"\n",
    "agent.invoke({\"input\": query})\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf93b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38673428",
   "metadata": {},
   "source": [
    "### chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4cd9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a more complex chain\n",
    "def create_story_chain():\n",
    "    # Template for story generation\n",
    "    story_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a creative storyteller. Write a short, engaging story based on the given theme.\"),\n",
    "        (\"user\", \"Theme: {theme}\\nMain character: {character}\\nSetting: {setting}\")\n",
    "    ])\n",
    "    \n",
    "    # Template for story analysis\n",
    "    analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a literary critic. Analyze the following story and provide insights.\"),\n",
    "        (\"user\", \"{story}\")\n",
    "    ])\n",
    "    \n",
    "    # Build the chain - Method 1: Sequential execution\n",
    "    story_chain = (\n",
    "        story_prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Create a function to pass the story to analysis\n",
    "    def analyze_story(story_text):\n",
    "        return {\"story\": story_text}\n",
    "    \n",
    "    analysis_chain = (\n",
    "        story_chain\n",
    "        | RunnableLambda(analyze_story)\n",
    "        | analysis_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return analysis_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb3a6a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a creative storyteller. Write a short, engaging story based on the given theme.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme: {theme}\\nMain character: {character}\\nSetting: {setting}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1589a6990>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x158c97200>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyze_story)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a literary critic. Analyze the following story and provide insights.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='{story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1589a6990>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x158c97200>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=create_story_chain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef1a9195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story and Analysis:\n",
      "**Analysis of \"The Boy with a Golden Smile\"**\n",
      "\n",
      "\"The Boy with a Golden Smile\" is a heartwarming and uplifting story that embodies the spirit of childhood innocence, kindness, and wonder. On the surface, it appears to be a simple tale of a young boy's adventures in a quaint village, but upon closer examination, it reveals itself to be a rich and nuanced exploration of the human experience.\n",
      "\n",
      "**Themes**\n",
      "\n",
      "One of the primary themes of the story is the importance of empathy and compassion. Ram's kindness towards the wounded bird, Kali, sets off a chain of events that not only helps the bird recover but also brings the community together. This theme is reinforced by the villagers' amazement and admiration for Ram's selflessness and gentle nature. The story suggests that even small acts of kindness can have a profound impact on those around us.\n",
      "\n",
      "Another significant theme is the power of curiosity and exploration. Ram's love for nature and animals drives him to discover new species, learn about their habitats, and develop a deeper appreciation for the world around him. This theme is closely tied to the idea of childhood innocence, as Ram's wonder and awe for the natural world are unbridled and unassuming.\n",
      "\n",
      "**Character Analysis**\n",
      "\n",
      "Ram is the central character of the story, and his personality is expertly woven throughout the narrative. He is depicted as a bright-eyed, mischievous, and kind-hearted young boy who is always eager to learn and explore. His love for nature and animals is infectious, and his compassion towards Kali sets the tone for the rest of the story.\n",
      "\n",
      "Mr. Kumar, the teacher, is also an important character in the story. His patience and kind heart are highlighted as he praises Ram for his quick thinking and accuracy. This character serves as a foil to Ram's enthusiasm, providing a sense of stability and guidance.\n",
      "\n",
      "**Symbolism**\n",
      "\n",
      "The wounded bird, Kali, is a powerful symbol of Ram's compassion and kindness. The bird's recovery serves as a metaphor for the healing power of love and care. Kali's vibrant plumage also represents the beauty and diversity of the natural world, which Ram is eager to explore and learn about.\n",
      "\n",
      "The village of Kalyanpur is also a symbol of simplicity and innocence. The story portrays the village as a peaceful and idyllic place where children can run free and explore the world around them. This setting serves as a backdrop for Ram's adventures and provides a sense of continuity and stability.\n",
      "\n",
      "**Style and Structure**\n",
      "\n",
      "The story is written in a lyrical and descriptive style, with vivid imagery and sensory details that transport the reader to the village of Kalyanpur. The narrative is structured in a non-linear fashion, with the story unfolding over several years, from Ram's childhood to his adulthood. This structure allows the reader to see the growth and development of Ram's character and appreciate the impact of his childhood experiences on his adult life.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "In conclusion, \"The Boy with a Golden Smile\" is a delightful and uplifting story that celebrates the power of kindness, curiosity, and exploration. Ram's adventures in the village of Kalyanpur serve as a reminder of the importance of empathy and compassion, and the story's themes and characters will resonate with readers of all ages. The narrative's lyrical style and non-linear structure add to its charm, making it a memorable and engaging read.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"theme\": \"Life of a boy\",\n",
    "    \"character\": \"Ram : A boy from school\",\n",
    "    \"setting\": \"village life\"\n",
    "})\n",
    "\n",
    "print(\"Story and Analysis:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14b637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
